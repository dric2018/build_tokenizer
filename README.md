# build_tokenizer
Building a tokenizer for custom dataset in order to perform some NLP tasks
